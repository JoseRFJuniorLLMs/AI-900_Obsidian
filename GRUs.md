**6. Gated Recurrent Units ([[GRUs]])**

* Uma variação de RNNs que simplifica LSTMs removendo as células de memória.
* Utilizam gates de atenção e esquecimento para controlar o fluxo de informação.