A MST é um tipo de transformador que processa o texto em diferentes escalas e níveis de detalhe. Isso permite ao modelo
capturar informações relevantes a diferentes níveis, desde as palavras individuais até as frases e textos inteiros.

Os autores também utilizaram uma técnica chamada "[[Layer-Wise Training]]" para treinar os embeddings do modelo em camadas
separadas. Isso ajuda a evitar o [[Overfitting]] e permite ao modelo aprender relações mais complexas entre as palavras e textos.

A combinação dessas técnicas permitiu ao GPT-4 gerar embeddings de alta qualidade que podem capturar informações relevantes sobre o contexto em que as palavras e textos são utilizados.

Além disso, o GPT-4 também utiliza uma técnica chamada "Knowledge Distillation" para transferir conhecimento do modelo treinado para modelos mais pequenos. Isso permite ao modelo gerar embeddings de alta qualidade mesmo em situações onde não há acesso a grande quantidade de dados de treinamento.

É importante notar que o GPT-4 é uma variação do GPT-3 e utiliza as mesmas técnicas de embedding que o modelo original, com algumas ajustes para melhorar a performance e a eficiência.